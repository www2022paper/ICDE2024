{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeb09687-b291-4907-b139-026afbc1c94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 23:02:39.760280: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-24 23:02:39.816332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-24 23:02:39.816362: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-24 23:02:39.816398: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-24 23:02:39.824699: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-24 23:02:41.619261: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n",
      "CPU times: user 4.59 s, sys: 1.87 s, total: 6.46 s\n",
      "Wall time: 8.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from catenets.models.jax import TNet, SNet, OFFSET_NAME, FlexTENet, OffsetNet, SNet1, SNet2\n",
    "from catenets.experiment_utils.simulation_utils import simulate_treatment_setup\n",
    "\n",
    "#catenets (SNet, FlexTENet, OffsetNet, TNet, SNet1 (TARNet), SNet2 (DragonNet)\n",
    "def plot_loss(history, *losses):\n",
    "    for loss in losses:\n",
    "        plt.plot(history.history[loss], label=loss)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def scaling(x, min, max):\n",
    "    return np.where(x < min, 0.0, np.where(x > max, 1.0, (x - min) / (max - min)))\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # \n",
    "    patience=500,        # \n",
    "    verbose=1,          # \n",
    "    mode='min',         # \n",
    "    restore_best_weights=True  # \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "803362e2-99b9-4faf-b8fa-37631083116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = \"../data\"\n",
    "file_criteo = SAVE_DIR + \"/criteo-uplift-v2.1.csv\"\n",
    "df_criteo_ori = pd.read_csv(file_criteo, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e424f27e-16a5-41d7-9424-9d41fe3728c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1467857 (1467857, 12) (524236, 12) 2096939 (104846, 12)\n",
      "1467857 (1467857, 12) (327160, 12) 2096939 (65226, 12)\n",
      "CPU times: user 1.03 s, sys: 342 ms, total: 1.38 s\n",
      "Wall time: 2.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sample = 0.15\n",
    "random_state=20220720\n",
    "df_criteo=df_criteo_ori.sample(frac=sample, random_state=random_state).reset_index(drop=True)\n",
    "X = df_criteo[['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11']].values\n",
    "\n",
    "X[:, 0] = scaling(X[:, 0], min=np.min(X[:, 0]), max=np.max(X[:, 0]))\n",
    "X[:, 1] = scaling(X[:, 1], min=np.min(X[:, 1]), max=np.max(X[:, 1]))\n",
    "X[:, 2] = scaling(X[:, 2], min=np.min(X[:, 2]), max=np.max(X[:, 2]))\n",
    "X[:, 3] = scaling(X[:, 3], min=np.min(X[:, 3]), max=np.max(X[:, 3]))\n",
    "X[:, 4] = scaling(X[:, 4], min=np.min(X[:, 4]), max=np.max(X[:, 4]))\n",
    "X[:, 5] = scaling(X[:, 5], min=np.min(X[:, 5]), max=np.max(X[:, 5]))\n",
    "X[:, 6] = scaling(X[:, 6], min=np.min(X[:, 6]), max=np.max(X[:, 6]))\n",
    "X[:, 7] = scaling(X[:, 7], min=np.min(X[:, 7]), max=np.max(X[:, 7]))\n",
    "X[:, 8] = scaling(X[:, 8], min=np.min(X[:, 8]), max=np.max(X[:, 8]))\n",
    "X[:, 9] = scaling(X[:, 9], min=np.min(X[:, 9]), max=np.max(X[:, 9]))\n",
    "X[:, 10] = scaling(X[:, 10], min=np.min(X[:, 10]), max=np.max(X[:, 10]))\n",
    "X[:, 11] = scaling(X[:, 11], min=np.min(X[:, 11]), max=np.max(X[:, 11]))\n",
    "\n",
    "T = df_criteo['treatment'].values.reshape(-1, 1)\n",
    "Y_visit = df_criteo['visit'].values.reshape(-1, 1)\n",
    "Y_conv = df_criteo['conversion'].values.reshape(-1, 1)\n",
    "\n",
    "T.shape, Y_visit.shape, Y_conv.shape\n",
    "\n",
    "\n",
    "# calculate len\n",
    "train_len = int(len(X) * 0.70)\n",
    "cali_len = int(len(X) * 0.05)\n",
    "test_len = len(X) - train_len - cali_len\n",
    "\n",
    "# obtain train set\n",
    "X_train = X[:train_len, :]\n",
    "T_train = T[:train_len, :]\n",
    "Y_visit_train = Y_visit[:train_len, :]\n",
    "Y_conv_train = Y_conv[:train_len, :]\n",
    "\n",
    "# obtain calibration set\n",
    "X_cali = X[train_len:train_len+cali_len, :]\n",
    "T_cali = T[train_len:train_len+cali_len, :]\n",
    "Y_visit_cali = Y_visit[train_len:train_len+cali_len, :]\n",
    "Y_conv_cali = Y_conv[train_len:train_len+cali_len, :]\n",
    "\n",
    "# obtain test set\n",
    "X_test = X[train_len+cali_len:, :]\n",
    "T_test = T[train_len+cali_len:, :]\n",
    "Y_visit_test = Y_visit[train_len+cali_len:, :]\n",
    "Y_conv_test = Y_conv[train_len+cali_len:, :]\n",
    "\n",
    "print(train_len, X_train.shape, X_test.shape, len(X), X_cali.shape)\n",
    "\n",
    "# make covariate shift\n",
    "condition_cali = (X_cali[:, 0] > 0.3) & (X_cali[:, 1] < 0.7)\n",
    "X_cali = X_cali[condition_cali]\n",
    "T_cali = T_cali[condition_cali]\n",
    "Y_visit_cali = Y_visit_cali[condition_cali]\n",
    "Y_conv_cali = Y_conv_cali[condition_cali]\n",
    "\n",
    "condition_test = (X_test[:, 0] > 0.3) & (X_test[:, 1] < 0.7)\n",
    "X_test = X_test[condition_test]\n",
    "T_test = T_test[condition_test]\n",
    "Y_visit_test = Y_visit_test[condition_test]\n",
    "Y_conv_test = Y_conv_test[condition_test]\n",
    "\n",
    "print(train_len, X_train.shape, X_test.shape, len(X), X_cali.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec34a70-a710-4c03-9c71-978b5d59bd20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29fa88cd-b1ce-4c8b-8497-f9529b758a56",
   "metadata": {},
   "source": [
    "### SNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c91a8815-dd85-4873-a9bd-3c73fee7ca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit\n",
    "s = SNet(batch_size=10000,n_iter=300)\n",
    "s.fit(X_train, Y_visit_train.reshape(-1), T_train.reshape(-1))\n",
    "cate_pred_s_visit = s.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b28ac85-30e3-4620-b3c8-593486146174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv\n",
    "s = SNet(batch_size=10000,n_iter=300)\n",
    "s.fit(X_train, Y_conv_train.reshape(-1), T_train.reshape(-1))\n",
    "cate_pred_s_conv = s.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5a9361d-f3ef-4889-af54-204ad65b7253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCC =  0.5504909236631894\n"
     ]
    }
   ],
   "source": [
    "import sklearn \n",
    "import sklearn.metrics\n",
    "from metric.Metric import *\n",
    "\n",
    "direct_ratio_SL_aucc_list = []\n",
    "roi_slearner_pre = cate_pred_s_conv / np.where(abs(cate_pred_s_visit) < 1e-6, 1e-6, cate_pred_s_visit)\n",
    "\n",
    "direct_ratio_SL_aucc = get_uplift_model_aucc_no_show(t=(T_test > 0.5).flatten(), y_reward=Y_conv_test.flatten(), y_cost=Y_visit_test.flatten(), roi_pred=roi_slearner_pre.flatten(), quantile=200)\n",
    "direct_ratio_SL_aucc_list.append(direct_ratio_SL_aucc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0276c919-17a1-4182-a9ea-06f55f15f012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aucc =  0.5504909236631894\n"
     ]
    }
   ],
   "source": [
    "# store test aucc for pic \n",
    "import pandas as pd\n",
    "\n",
    "def get_aucc_cost_curve(aucc_list):\n",
    "    delta_cost_list_group = np.array([aucc[1] for aucc in aucc_list])\n",
    "    delta_reward_list_group = np.array([aucc[2] for aucc in aucc_list])\n",
    "    \n",
    "    avg_delta_cost_list = np.mean(delta_cost_list_group, axis=0)\n",
    "    avg_delta_reward_list = np.mean(delta_reward_list_group, axis=0)\n",
    "    \n",
    "    df_aucc_cost_curve = pd.DataFrame(avg_delta_cost_list, columns=['delta_cost'])\n",
    "    df_aucc_cost_curve['delta_reward'] = avg_delta_reward_list\n",
    "    \n",
    "    return df_aucc_cost_curve\n",
    "\n",
    "A_direct_ratio_SL_aucc_list = get_aucc_cost_curve(direct_ratio_SL_aucc_list)\n",
    "print(\"aucc = \", np.sum(A_direct_ratio_SL_aucc_list['delta_reward'].values) / (A_direct_ratio_SL_aucc_list['delta_reward'].values[-1] * 201))\n",
    "A_direct_ratio_SL_aucc_list.to_csv(\"../figure/CRI_d_snet_aucc_list.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd16e402-20b1-45e3-a47c-404352b6cab5",
   "metadata": {},
   "source": [
    "### OffsetNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c8699e9-fe4e-4731-b400-6555a0d38cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCC =  0.5196008712453385\n",
      "aucc =  0.5196008712453385\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# visit\n",
    "s = OffsetNet(batch_size=10000,n_iter=300)\n",
    "s.fit(X_train, Y_visit_train.reshape(-1), T_train.reshape(-1))\n",
    "cate_pred_s_visit = s.predict(X_test)\n",
    "\n",
    "# conv\n",
    "s = OffsetNet(batch_size=10000,n_iter=300)\n",
    "s.fit(X_train, Y_conv_train.reshape(-1), T_train.reshape(-1))\n",
    "cate_pred_s_conv = s.predict(X_test)\n",
    "\n",
    "\n",
    "import sklearn \n",
    "import sklearn.metrics\n",
    "from metric.Metric import *\n",
    "\n",
    "direct_ratio_SL_aucc_list = []\n",
    "roi_slearner_pre = cate_pred_s_conv / np.where(abs(cate_pred_s_visit) < 1e-6, 1e-6, cate_pred_s_visit)\n",
    "\n",
    "direct_ratio_SL_aucc = get_uplift_model_aucc_no_show(t=(T_test > 0.5).flatten(), y_reward=Y_conv_test.flatten(), y_cost=Y_visit_test.flatten(), roi_pred=roi_slearner_pre.flatten(), quantile=200)\n",
    "direct_ratio_SL_aucc_list.append(direct_ratio_SL_aucc)\n",
    "\n",
    "# store test aucc for pic \n",
    "import pandas as pd\n",
    "\n",
    "def get_aucc_cost_curve(aucc_list):\n",
    "    delta_cost_list_group = np.array([aucc[1] for aucc in aucc_list])\n",
    "    delta_reward_list_group = np.array([aucc[2] for aucc in aucc_list])\n",
    "    \n",
    "    avg_delta_cost_list = np.mean(delta_cost_list_group, axis=0)\n",
    "    avg_delta_reward_list = np.mean(delta_reward_list_group, axis=0)\n",
    "    \n",
    "    df_aucc_cost_curve = pd.DataFrame(avg_delta_cost_list, columns=['delta_cost'])\n",
    "    df_aucc_cost_curve['delta_reward'] = avg_delta_reward_list\n",
    "    \n",
    "    return df_aucc_cost_curve\n",
    "\n",
    "A_direct_ratio_SL_aucc_list = get_aucc_cost_curve(direct_ratio_SL_aucc_list)\n",
    "print(\"aucc = \", np.sum(A_direct_ratio_SL_aucc_list['delta_reward'].values) / (A_direct_ratio_SL_aucc_list['delta_reward'].values[-1] * 201))\n",
    "A_direct_ratio_SL_aucc_list.to_csv(\"../figure/CRI_d_OffsetNet_aucc_list.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40548e0-bfca-482f-b4df-22b689105f93",
   "metadata": {},
   "source": [
    "### SNet1 (TARNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58b47f07-36b2-4a6c-a08c-5b9977a15c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCC =  0.5371991364330178\n",
      "aucc =  0.5371991364330178\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# visit\n",
    "s = SNet1(batch_size=10000,n_iter=300)\n",
    "s.fit(X_train, Y_visit_train.reshape(-1), T_train.reshape(-1))\n",
    "cate_pred_s_visit = s.predict(X_test)\n",
    "\n",
    "# conv\n",
    "s = SNet1(batch_size=10000,n_iter=300)\n",
    "s.fit(X_train, Y_conv_train.reshape(-1), T_train.reshape(-1))\n",
    "cate_pred_s_conv = s.predict(X_test)\n",
    "\n",
    "\n",
    "import sklearn \n",
    "import sklearn.metrics\n",
    "from metric.Metric import *\n",
    "\n",
    "direct_ratio_SL_aucc_list = []\n",
    "roi_slearner_pre = cate_pred_s_conv / np.where(abs(cate_pred_s_visit) < 1e-6, 1e-6, cate_pred_s_visit)\n",
    "\n",
    "direct_ratio_SL_aucc = get_uplift_model_aucc_no_show(t=(T_test > 0.5).flatten(), y_reward=Y_conv_test.flatten(), y_cost=Y_visit_test.flatten(), roi_pred=roi_slearner_pre.flatten(), quantile=200)\n",
    "direct_ratio_SL_aucc_list.append(direct_ratio_SL_aucc)\n",
    "\n",
    "# store test aucc for pic \n",
    "import pandas as pd\n",
    "\n",
    "def get_aucc_cost_curve(aucc_list):\n",
    "    delta_cost_list_group = np.array([aucc[1] for aucc in aucc_list])\n",
    "    delta_reward_list_group = np.array([aucc[2] for aucc in aucc_list])\n",
    "    \n",
    "    avg_delta_cost_list = np.mean(delta_cost_list_group, axis=0)\n",
    "    avg_delta_reward_list = np.mean(delta_reward_list_group, axis=0)\n",
    "    \n",
    "    df_aucc_cost_curve = pd.DataFrame(avg_delta_cost_list, columns=['delta_cost'])\n",
    "    df_aucc_cost_curve['delta_reward'] = avg_delta_reward_list\n",
    "    \n",
    "    return df_aucc_cost_curve\n",
    "\n",
    "A_direct_ratio_SL_aucc_list = get_aucc_cost_curve(direct_ratio_SL_aucc_list)\n",
    "print(\"aucc = \", np.sum(A_direct_ratio_SL_aucc_list['delta_reward'].values) / (A_direct_ratio_SL_aucc_list['delta_reward'].values[-1] * 201))\n",
    "A_direct_ratio_SL_aucc_list.to_csv(\"../figure/CRI_d_SNet1_aucc_list.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b41d77b-fa2c-45d2-9102-806df126aee2",
   "metadata": {},
   "source": [
    "### SNet2 (DragonNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b379569b-afbe-4879-ba41-71113847bae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCC =  0.5374919126341383\n",
      "aucc =  0.5374919126341383\n",
      "CPU times: user 44min 7s, sys: 35min 44s, total: 1h 19min 52s\n",
      "Wall time: 8min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# visit\n",
    "s = SNet2(batch_size=10000,n_iter=300)\n",
    "s.fit(X_train, Y_visit_train.reshape(-1), T_train.reshape(-1))\n",
    "cate_pred_s_visit = s.predict(X_test)\n",
    "\n",
    "# conv\n",
    "s = SNet2(batch_size=10000,n_iter=300)\n",
    "s.fit(X_train, Y_conv_train.reshape(-1), T_train.reshape(-1))\n",
    "cate_pred_s_conv = s.predict(X_test)\n",
    "\n",
    "\n",
    "import sklearn \n",
    "import sklearn.metrics\n",
    "from metric.Metric import *\n",
    "\n",
    "direct_ratio_SL_aucc_list = []\n",
    "roi_slearner_pre = cate_pred_s_conv / np.where(abs(cate_pred_s_visit) < 1e-6, 1e-6, cate_pred_s_visit)\n",
    "\n",
    "direct_ratio_SL_aucc = get_uplift_model_aucc_no_show(t=(T_test > 0.5).flatten(), y_reward=Y_conv_test.flatten(), y_cost=Y_visit_test.flatten(), roi_pred=roi_slearner_pre.flatten(), quantile=200)\n",
    "direct_ratio_SL_aucc_list.append(direct_ratio_SL_aucc)\n",
    "\n",
    "# store test aucc for pic \n",
    "import pandas as pd\n",
    "\n",
    "def get_aucc_cost_curve(aucc_list):\n",
    "    delta_cost_list_group = np.array([aucc[1] for aucc in aucc_list])\n",
    "    delta_reward_list_group = np.array([aucc[2] for aucc in aucc_list])\n",
    "    \n",
    "    avg_delta_cost_list = np.mean(delta_cost_list_group, axis=0)\n",
    "    avg_delta_reward_list = np.mean(delta_reward_list_group, axis=0)\n",
    "    \n",
    "    df_aucc_cost_curve = pd.DataFrame(avg_delta_cost_list, columns=['delta_cost'])\n",
    "    df_aucc_cost_curve['delta_reward'] = avg_delta_reward_list\n",
    "    \n",
    "    return df_aucc_cost_curve\n",
    "\n",
    "A_direct_ratio_SL_aucc_list = get_aucc_cost_curve(direct_ratio_SL_aucc_list)\n",
    "print(\"aucc = \", np.sum(A_direct_ratio_SL_aucc_list['delta_reward'].values) / (A_direct_ratio_SL_aucc_list['delta_reward'].values[-1] * 201))\n",
    "A_direct_ratio_SL_aucc_list.to_csv(\"../figure/CRI_d_SNet2_aucc_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8c0040-b193-4523-a59e-5b9f10ecfa32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
