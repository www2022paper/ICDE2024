{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b5253fb-8c45-4439-9d6f-320a6ba5cf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-20 15:35:10.141458: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-20 15:35:10.176843: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-20 15:35:10.176867: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-20 15:35:10.176889: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-20 15:35:10.183627: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-20 15:35:10.966583: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n",
      "CPU times: user 2.6 s, sys: 3.42 s, total: 6.02 s\n",
      "Wall time: 2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_loss(history, *losses):\n",
    "    for loss in losses:\n",
    "        plt.plot(history.history[loss], label=loss)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def scaling(x, min, max):\n",
    "    return np.where(x < min, 0.0, np.where(x > max, 1.0, (x - min) / (max - min)))\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # \n",
    "    patience=50,        # \n",
    "    verbose=1,          # \n",
    "    mode='min',         # \n",
    "    restore_best_weights=True  # \n",
    ")\n",
    "\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "class TerminateOnNegative(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        loss = logs.get('loss')\n",
    "        if loss is not None:\n",
    "            if loss < -0.5:\n",
    "                print('Negative loss detected and terminating training')\n",
    "                self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b71a2eef-9d0f-42af-8791-a15b3970e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = \"../data\"\n",
    "file_criteo = SAVE_DIR + \"/MT-LIFT/train.csv\"\n",
    "df_criteo_ori = pd.read_csv(file_criteo, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f39b4166-6354-4734-9c7b-02ca19d6be46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click</th>\n",
       "      <th>conversion</th>\n",
       "      <th>treatment</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>f13</th>\n",
       "      <th>f14</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "      <th>f31</th>\n",
       "      <th>f32</th>\n",
       "      <th>f33</th>\n",
       "      <th>f34</th>\n",
       "      <th>f35</th>\n",
       "      <th>f36</th>\n",
       "      <th>f37</th>\n",
       "      <th>f38</th>\n",
       "      <th>f39</th>\n",
       "      <th>f40</th>\n",
       "      <th>f41</th>\n",
       "      <th>f42</th>\n",
       "      <th>f43</th>\n",
       "      <th>f44</th>\n",
       "      <th>f45</th>\n",
       "      <th>f46</th>\n",
       "      <th>f47</th>\n",
       "      <th>f48</th>\n",
       "      <th>f49</th>\n",
       "      <th>f50</th>\n",
       "      <th>f51</th>\n",
       "      <th>f52</th>\n",
       "      <th>f53</th>\n",
       "      <th>f54</th>\n",
       "      <th>f55</th>\n",
       "      <th>f56</th>\n",
       "      <th>f57</th>\n",
       "      <th>f58</th>\n",
       "      <th>f59</th>\n",
       "      <th>f60</th>\n",
       "      <th>f61</th>\n",
       "      <th>f62</th>\n",
       "      <th>f63</th>\n",
       "      <th>f64</th>\n",
       "      <th>f65</th>\n",
       "      <th>f66</th>\n",
       "      <th>f67</th>\n",
       "      <th>f68</th>\n",
       "      <th>f69</th>\n",
       "      <th>f70</th>\n",
       "      <th>f71</th>\n",
       "      <th>f72</th>\n",
       "      <th>f73</th>\n",
       "      <th>f74</th>\n",
       "      <th>f75</th>\n",
       "      <th>f76</th>\n",
       "      <th>f77</th>\n",
       "      <th>f78</th>\n",
       "      <th>f79</th>\n",
       "      <th>f80</th>\n",
       "      <th>f81</th>\n",
       "      <th>f82</th>\n",
       "      <th>f83</th>\n",
       "      <th>f84</th>\n",
       "      <th>f85</th>\n",
       "      <th>f86</th>\n",
       "      <th>f87</th>\n",
       "      <th>f88</th>\n",
       "      <th>f89</th>\n",
       "      <th>f90</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4563026.0</td>\n",
       "      <td>4563026.0</td>\n",
       "      <td>4563026.0</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "      <td>4.563026e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.329111e-01</td>\n",
       "      <td>6.808859e-02</td>\n",
       "      <td>2.017062e+00</td>\n",
       "      <td>1.297720e-14</td>\n",
       "      <td>-4.963344e-14</td>\n",
       "      <td>1.297720e-14</td>\n",
       "      <td>1.858299e-15</td>\n",
       "      <td>1.132534e+01</td>\n",
       "      <td>4.847851e+01</td>\n",
       "      <td>1.226735e-14</td>\n",
       "      <td>4.893479e-14</td>\n",
       "      <td>2.055761e-01</td>\n",
       "      <td>-7.029400e-15</td>\n",
       "      <td>-1.531296e-14</td>\n",
       "      <td>-9.767474e-17</td>\n",
       "      <td>-1.433504e-15</td>\n",
       "      <td>-7.158479e-16</td>\n",
       "      <td>1.729946e-15</td>\n",
       "      <td>-1.000455e-16</td>\n",
       "      <td>5.403623e-16</td>\n",
       "      <td>1.206037e-15</td>\n",
       "      <td>3.792545e-16</td>\n",
       "      <td>5.069362e-17</td>\n",
       "      <td>8.647477e-16</td>\n",
       "      <td>-2.808954e-15</td>\n",
       "      <td>1.551954e-15</td>\n",
       "      <td>1.049387e-15</td>\n",
       "      <td>-1.744694e-15</td>\n",
       "      <td>1.477405e-15</td>\n",
       "      <td>3.019315e-16</td>\n",
       "      <td>1.888722e-14</td>\n",
       "      <td>-2.648952e-15</td>\n",
       "      <td>-1.580736e-15</td>\n",
       "      <td>-4.773777e-16</td>\n",
       "      <td>2.719365e-14</td>\n",
       "      <td>-1.152346e-15</td>\n",
       "      <td>1.982184e-15</td>\n",
       "      <td>2.989136e-15</td>\n",
       "      <td>-4.611154e-14</td>\n",
       "      <td>1.141461e-13</td>\n",
       "      <td>5.541246e-14</td>\n",
       "      <td>-1.341142e-13</td>\n",
       "      <td>-4.068228e-15</td>\n",
       "      <td>1.854724e-15</td>\n",
       "      <td>2.773904e-15</td>\n",
       "      <td>1.543437e-15</td>\n",
       "      <td>-6.015715e-15</td>\n",
       "      <td>3.699764e-15</td>\n",
       "      <td>-8.055069e-15</td>\n",
       "      <td>3.585170e-14</td>\n",
       "      <td>2.412674e-14</td>\n",
       "      <td>-2.079914e-15</td>\n",
       "      <td>1.707669e-14</td>\n",
       "      <td>-1.223745e-14</td>\n",
       "      <td>1.835816e-14</td>\n",
       "      <td>-1.023446e-14</td>\n",
       "      <td>3.965333e-15</td>\n",
       "      <td>6.341540e-14</td>\n",
       "      <td>2.078108e-14</td>\n",
       "      <td>1.140032e-13</td>\n",
       "      <td>4.469076e-14</td>\n",
       "      <td>5.683151e-15</td>\n",
       "      <td>-1.386516e-14</td>\n",
       "      <td>-1.821274e-13</td>\n",
       "      <td>-1.448995e-13</td>\n",
       "      <td>8.104543e-15</td>\n",
       "      <td>-3.443619e-13</td>\n",
       "      <td>1.545818e-13</td>\n",
       "      <td>-4.948753e-14</td>\n",
       "      <td>2.046312e-14</td>\n",
       "      <td>8.860513e-14</td>\n",
       "      <td>1.135963e-14</td>\n",
       "      <td>3.641478e-15</td>\n",
       "      <td>-3.217927e-14</td>\n",
       "      <td>3.388089e-14</td>\n",
       "      <td>-8.494551e-15</td>\n",
       "      <td>2.398633e-14</td>\n",
       "      <td>-5.253318e-14</td>\n",
       "      <td>-6.736687e-15</td>\n",
       "      <td>1.916000e-13</td>\n",
       "      <td>-1.341227e-13</td>\n",
       "      <td>-1.148650e-13</td>\n",
       "      <td>9.186658e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.054864e-13</td>\n",
       "      <td>-1.436688e-13</td>\n",
       "      <td>7.997414e-14</td>\n",
       "      <td>3.189143e-14</td>\n",
       "      <td>3.382649e-14</td>\n",
       "      <td>4.331797e-16</td>\n",
       "      <td>-8.919827e-14</td>\n",
       "      <td>-3.326532e-13</td>\n",
       "      <td>-1.550075e-13</td>\n",
       "      <td>-2.684486e-13</td>\n",
       "      <td>4.524844e-14</td>\n",
       "      <td>-5.131995e-15</td>\n",
       "      <td>-3.978028e-14</td>\n",
       "      <td>-2.948881e-15</td>\n",
       "      <td>3.773022e-14</td>\n",
       "      <td>-7.525065e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.712551e-01</td>\n",
       "      <td>2.518979e-01</td>\n",
       "      <td>1.476708e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.345643e+00</td>\n",
       "      <td>3.750672e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.129533e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.693189e+01</td>\n",
       "      <td>-1.859227e+01</td>\n",
       "      <td>-1.693189e+01</td>\n",
       "      <td>-1.762771e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-9.178679e+00</td>\n",
       "      <td>-1.843498e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-5.200102e-01</td>\n",
       "      <td>-7.789905e-01</td>\n",
       "      <td>-5.813451e-01</td>\n",
       "      <td>-5.791204e-01</td>\n",
       "      <td>-5.811981e-01</td>\n",
       "      <td>-5.869710e-01</td>\n",
       "      <td>-5.800899e-01</td>\n",
       "      <td>-5.300433e-01</td>\n",
       "      <td>-5.297176e-01</td>\n",
       "      <td>-5.329927e-01</td>\n",
       "      <td>-5.291009e-01</td>\n",
       "      <td>-2.051438e+00</td>\n",
       "      <td>-2.653362e+00</td>\n",
       "      <td>-2.330228e+00</td>\n",
       "      <td>-2.704713e+00</td>\n",
       "      <td>-2.528168e+00</td>\n",
       "      <td>-1.517285e+00</td>\n",
       "      <td>-9.260579e-01</td>\n",
       "      <td>-1.073056e+00</td>\n",
       "      <td>-1.071262e+00</td>\n",
       "      <td>-1.003023e+00</td>\n",
       "      <td>-8.562420e-01</td>\n",
       "      <td>-5.557327e+01</td>\n",
       "      <td>-5.558729e-01</td>\n",
       "      <td>-5.638750e-01</td>\n",
       "      <td>-5.643321e-01</td>\n",
       "      <td>-1.099974e+00</td>\n",
       "      <td>-1.039632e+00</td>\n",
       "      <td>-1.055675e+00</td>\n",
       "      <td>-1.187171e+00</td>\n",
       "      <td>-6.070271e-01</td>\n",
       "      <td>-5.843887e-01</td>\n",
       "      <td>-6.042899e-01</td>\n",
       "      <td>-5.967528e-01</td>\n",
       "      <td>-7.773987e+01</td>\n",
       "      <td>-4.972883e+00</td>\n",
       "      <td>-8.965087e-01</td>\n",
       "      <td>-9.136077e-01</td>\n",
       "      <td>-3.941843e+00</td>\n",
       "      <td>-4.073446e+00</td>\n",
       "      <td>-3.897007e+00</td>\n",
       "      <td>-2.379831e-01</td>\n",
       "      <td>-3.036693e-01</td>\n",
       "      <td>-2.762787e-01</td>\n",
       "      <td>-2.998660e-01</td>\n",
       "      <td>-2.180436e-01</td>\n",
       "      <td>-2.551730e-01</td>\n",
       "      <td>-2.446223e-01</td>\n",
       "      <td>-2.366415e-01</td>\n",
       "      <td>-2.546120e-01</td>\n",
       "      <td>-2.883068e-01</td>\n",
       "      <td>-4.042764e-01</td>\n",
       "      <td>-3.554782e-01</td>\n",
       "      <td>-4.104357e-01</td>\n",
       "      <td>-3.898364e-01</td>\n",
       "      <td>-2.386262e-01</td>\n",
       "      <td>-3.050631e-01</td>\n",
       "      <td>-2.779237e-01</td>\n",
       "      <td>-3.008847e-01</td>\n",
       "      <td>-2.178310e-01</td>\n",
       "      <td>-2.551620e-01</td>\n",
       "      <td>-2.444910e-01</td>\n",
       "      <td>-2.370746e-01</td>\n",
       "      <td>-2.545106e-01</td>\n",
       "      <td>-2.883169e-01</td>\n",
       "      <td>-4.043490e-01</td>\n",
       "      <td>-3.554969e-01</td>\n",
       "      <td>-4.104756e-01</td>\n",
       "      <td>-3.898741e-01</td>\n",
       "      <td>-1.046829e+00</td>\n",
       "      <td>-2.112493e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.589764e-01</td>\n",
       "      <td>-4.599073e-01</td>\n",
       "      <td>-4.255688e-01</td>\n",
       "      <td>-4.426721e-01</td>\n",
       "      <td>-4.566893e-01</td>\n",
       "      <td>-3.389437e-01</td>\n",
       "      <td>-3.887242e-01</td>\n",
       "      <td>-3.803880e-01</td>\n",
       "      <td>-3.666181e-01</td>\n",
       "      <td>-3.934802e-01</td>\n",
       "      <td>-3.347722e-01</td>\n",
       "      <td>-4.481766e-01</td>\n",
       "      <td>-3.995944e-01</td>\n",
       "      <td>-4.602061e-01</td>\n",
       "      <td>-4.313790e-01</td>\n",
       "      <td>-4.935589e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.227170e-01</td>\n",
       "      <td>-6.600557e-02</td>\n",
       "      <td>-3.227170e-01</td>\n",
       "      <td>-4.720464e-01</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>-4.414899e-01</td>\n",
       "      <td>-1.327731e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.742315e-01</td>\n",
       "      <td>-4.391719e-01</td>\n",
       "      <td>-5.067518e-01</td>\n",
       "      <td>-5.078609e-01</td>\n",
       "      <td>-5.066932e-01</td>\n",
       "      <td>-5.163263e-01</td>\n",
       "      <td>-5.067766e-01</td>\n",
       "      <td>-4.689983e-01</td>\n",
       "      <td>-4.691352e-01</td>\n",
       "      <td>-4.762073e-01</td>\n",
       "      <td>-4.700291e-01</td>\n",
       "      <td>-4.231365e-01</td>\n",
       "      <td>-4.747444e-01</td>\n",
       "      <td>-4.453657e-01</td>\n",
       "      <td>-4.904300e-01</td>\n",
       "      <td>-4.626802e-01</td>\n",
       "      <td>-5.158690e-01</td>\n",
       "      <td>-6.490426e-01</td>\n",
       "      <td>-7.202621e-01</td>\n",
       "      <td>-6.949100e-01</td>\n",
       "      <td>-6.833392e-01</td>\n",
       "      <td>-6.743675e-01</td>\n",
       "      <td>1.799426e-02</td>\n",
       "      <td>-4.964323e-01</td>\n",
       "      <td>-4.950359e-01</td>\n",
       "      <td>-4.969681e-01</td>\n",
       "      <td>-6.824317e-01</td>\n",
       "      <td>-1.039632e+00</td>\n",
       "      <td>-1.055675e+00</td>\n",
       "      <td>-1.187171e+00</td>\n",
       "      <td>-4.486505e-01</td>\n",
       "      <td>-4.371121e-01</td>\n",
       "      <td>-4.440061e-01</td>\n",
       "      <td>-4.417799e-01</td>\n",
       "      <td>-5.885686e-01</td>\n",
       "      <td>-7.685876e-01</td>\n",
       "      <td>-7.296643e-01</td>\n",
       "      <td>-7.660523e-01</td>\n",
       "      <td>-1.184756e+00</td>\n",
       "      <td>-1.207508e+00</td>\n",
       "      <td>-1.154147e+00</td>\n",
       "      <td>-2.379831e-01</td>\n",
       "      <td>-3.036693e-01</td>\n",
       "      <td>-2.754442e-01</td>\n",
       "      <td>-2.998660e-01</td>\n",
       "      <td>-2.180436e-01</td>\n",
       "      <td>-2.551730e-01</td>\n",
       "      <td>-2.446223e-01</td>\n",
       "      <td>-2.366415e-01</td>\n",
       "      <td>-2.546120e-01</td>\n",
       "      <td>-2.883068e-01</td>\n",
       "      <td>-4.042764e-01</td>\n",
       "      <td>-3.554782e-01</td>\n",
       "      <td>-4.104357e-01</td>\n",
       "      <td>-3.898364e-01</td>\n",
       "      <td>-2.386262e-01</td>\n",
       "      <td>-3.050631e-01</td>\n",
       "      <td>-2.770790e-01</td>\n",
       "      <td>-3.008847e-01</td>\n",
       "      <td>-2.178310e-01</td>\n",
       "      <td>-2.551620e-01</td>\n",
       "      <td>-2.444910e-01</td>\n",
       "      <td>-2.370746e-01</td>\n",
       "      <td>-2.545106e-01</td>\n",
       "      <td>-2.883169e-01</td>\n",
       "      <td>-4.043490e-01</td>\n",
       "      <td>-3.554969e-01</td>\n",
       "      <td>-4.104756e-01</td>\n",
       "      <td>-3.898741e-01</td>\n",
       "      <td>-1.046829e+00</td>\n",
       "      <td>-2.112493e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.589764e-01</td>\n",
       "      <td>-4.559252e-01</td>\n",
       "      <td>-4.255688e-01</td>\n",
       "      <td>-4.379482e-01</td>\n",
       "      <td>-4.554768e-01</td>\n",
       "      <td>-3.389437e-01</td>\n",
       "      <td>-3.887242e-01</td>\n",
       "      <td>-3.803880e-01</td>\n",
       "      <td>-3.625175e-01</td>\n",
       "      <td>-3.934802e-01</td>\n",
       "      <td>-3.347722e-01</td>\n",
       "      <td>-4.481766e-01</td>\n",
       "      <td>-3.995944e-01</td>\n",
       "      <td>-4.435368e-01</td>\n",
       "      <td>-4.313790e-01</td>\n",
       "      <td>-6.163251e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.931761e-01</td>\n",
       "      <td>2.148981e-01</td>\n",
       "      <td>1.931761e-01</td>\n",
       "      <td>-1.182385e-01</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>3.800000e+01</td>\n",
       "      <td>1.775416e-01</td>\n",
       "      <td>1.238355e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.242107e-01</td>\n",
       "      <td>-3.329785e-01</td>\n",
       "      <td>-3.579026e-01</td>\n",
       "      <td>-3.596122e-01</td>\n",
       "      <td>-3.580425e-01</td>\n",
       "      <td>-3.674336e-01</td>\n",
       "      <td>-3.580768e-01</td>\n",
       "      <td>-3.429138e-01</td>\n",
       "      <td>-3.430104e-01</td>\n",
       "      <td>-3.508452e-01</td>\n",
       "      <td>-3.437702e-01</td>\n",
       "      <td>-6.377253e-02</td>\n",
       "      <td>-8.690667e-02</td>\n",
       "      <td>-5.668423e-02</td>\n",
       "      <td>-8.737832e-02</td>\n",
       "      <td>-5.714237e-02</td>\n",
       "      <td>-1.128599e-01</td>\n",
       "      <td>-3.212653e-01</td>\n",
       "      <td>-2.666705e-01</td>\n",
       "      <td>-3.185583e-01</td>\n",
       "      <td>-2.884357e-01</td>\n",
       "      <td>-3.044184e-01</td>\n",
       "      <td>1.799426e-02</td>\n",
       "      <td>-3.577375e-01</td>\n",
       "      <td>-3.642416e-01</td>\n",
       "      <td>-3.622400e-01</td>\n",
       "      <td>-1.910238e-01</td>\n",
       "      <td>-1.918246e-01</td>\n",
       "      <td>-1.573124e-01</td>\n",
       "      <td>1.130237e-01</td>\n",
       "      <td>-2.809577e-01</td>\n",
       "      <td>-2.839296e-01</td>\n",
       "      <td>-2.837222e-01</td>\n",
       "      <td>-2.840021e-01</td>\n",
       "      <td>-9.233618e-02</td>\n",
       "      <td>3.592400e-01</td>\n",
       "      <td>-5.410105e-01</td>\n",
       "      <td>-5.728889e-01</td>\n",
       "      <td>3.227102e-01</td>\n",
       "      <td>-5.737069e-02</td>\n",
       "      <td>2.699179e-01</td>\n",
       "      <td>-2.379831e-01</td>\n",
       "      <td>-2.747727e-01</td>\n",
       "      <td>-2.562503e-01</td>\n",
       "      <td>-2.710554e-01</td>\n",
       "      <td>-2.180436e-01</td>\n",
       "      <td>-2.551730e-01</td>\n",
       "      <td>-2.446223e-01</td>\n",
       "      <td>-2.366415e-01</td>\n",
       "      <td>-2.546120e-01</td>\n",
       "      <td>-2.883068e-01</td>\n",
       "      <td>-4.042764e-01</td>\n",
       "      <td>-3.554782e-01</td>\n",
       "      <td>-4.104357e-01</td>\n",
       "      <td>-3.898364e-01</td>\n",
       "      <td>-2.386262e-01</td>\n",
       "      <td>-2.759106e-01</td>\n",
       "      <td>-2.576532e-01</td>\n",
       "      <td>-2.718582e-01</td>\n",
       "      <td>-2.178310e-01</td>\n",
       "      <td>-2.551620e-01</td>\n",
       "      <td>-2.444910e-01</td>\n",
       "      <td>-2.370746e-01</td>\n",
       "      <td>-2.545106e-01</td>\n",
       "      <td>-2.883169e-01</td>\n",
       "      <td>-4.043490e-01</td>\n",
       "      <td>-3.554969e-01</td>\n",
       "      <td>-4.104756e-01</td>\n",
       "      <td>-3.898741e-01</td>\n",
       "      <td>2.712521e-01</td>\n",
       "      <td>-2.112493e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.589764e-01</td>\n",
       "      <td>-3.782760e-01</td>\n",
       "      <td>-3.730483e-01</td>\n",
       "      <td>-3.695383e-01</td>\n",
       "      <td>-3.784807e-01</td>\n",
       "      <td>-3.389437e-01</td>\n",
       "      <td>-3.278027e-01</td>\n",
       "      <td>-3.502397e-01</td>\n",
       "      <td>-3.133113e-01</td>\n",
       "      <td>-3.370833e-01</td>\n",
       "      <td>-3.347722e-01</td>\n",
       "      <td>-3.522048e-01</td>\n",
       "      <td>-3.627339e-01</td>\n",
       "      <td>-3.479977e-01</td>\n",
       "      <td>-3.565239e-01</td>\n",
       "      <td>-8.473487e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>5.738536e-01</td>\n",
       "      <td>4.690489e-01</td>\n",
       "      <td>5.738536e-01</td>\n",
       "      <td>3.220868e-01</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>8.000000e+01</td>\n",
       "      <td>6.475521e-01</td>\n",
       "      <td>4.659804e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.581565e-02</td>\n",
       "      <td>9.179482e-02</td>\n",
       "      <td>-5.328518e-02</td>\n",
       "      <td>-5.739824e-02</td>\n",
       "      <td>-5.632193e-02</td>\n",
       "      <td>-3.592680e-02</td>\n",
       "      <td>-6.044801e-02</td>\n",
       "      <td>-1.121515e-01</td>\n",
       "      <td>-1.071805e-01</td>\n",
       "      <td>-9.039800e-02</td>\n",
       "      <td>-1.084009e-01</td>\n",
       "      <td>3.094021e-01</td>\n",
       "      <td>3.902922e-01</td>\n",
       "      <td>3.395765e-01</td>\n",
       "      <td>4.384148e-01</td>\n",
       "      <td>3.622780e-01</td>\n",
       "      <td>4.366980e-01</td>\n",
       "      <td>2.748252e-01</td>\n",
       "      <td>4.389164e-01</td>\n",
       "      <td>4.341451e-01</td>\n",
       "      <td>3.697367e-01</td>\n",
       "      <td>3.362756e-01</td>\n",
       "      <td>1.799426e-02</td>\n",
       "      <td>3.853335e-02</td>\n",
       "      <td>4.879281e-02</td>\n",
       "      <td>4.500623e-02</td>\n",
       "      <td>3.889102e-01</td>\n",
       "      <td>7.707515e-01</td>\n",
       "      <td>8.097377e-01</td>\n",
       "      <td>7.739473e-01</td>\n",
       "      <td>6.374419e-02</td>\n",
       "      <td>4.974978e-02</td>\n",
       "      <td>6.065000e-02</td>\n",
       "      <td>5.609672e-02</td>\n",
       "      <td>4.253302e-01</td>\n",
       "      <td>8.656915e-01</td>\n",
       "      <td>9.397362e-01</td>\n",
       "      <td>1.249727e+00</td>\n",
       "      <td>7.824007e-01</td>\n",
       "      <td>8.482851e-01</td>\n",
       "      <td>7.866388e-01</td>\n",
       "      <td>-1.389553e-01</td>\n",
       "      <td>-1.142364e-01</td>\n",
       "      <td>-1.360803e-01</td>\n",
       "      <td>-1.068351e-01</td>\n",
       "      <td>-2.180436e-01</td>\n",
       "      <td>-1.268027e-01</td>\n",
       "      <td>-1.240421e-01</td>\n",
       "      <td>-1.467639e-01</td>\n",
       "      <td>-1.396627e-01</td>\n",
       "      <td>-2.883068e-01</td>\n",
       "      <td>-1.519057e-01</td>\n",
       "      <td>-2.569043e-01</td>\n",
       "      <td>-1.359159e-01</td>\n",
       "      <td>-1.834617e-01</td>\n",
       "      <td>-1.389301e-01</td>\n",
       "      <td>-1.139523e-01</td>\n",
       "      <td>-1.360303e-01</td>\n",
       "      <td>-1.064071e-01</td>\n",
       "      <td>-2.178310e-01</td>\n",
       "      <td>-1.273467e-01</td>\n",
       "      <td>-1.244082e-01</td>\n",
       "      <td>-1.471972e-01</td>\n",
       "      <td>-1.400857e-01</td>\n",
       "      <td>-2.883169e-01</td>\n",
       "      <td>-1.519428e-01</td>\n",
       "      <td>-2.562679e-01</td>\n",
       "      <td>-1.352290e-01</td>\n",
       "      <td>-1.829469e-01</td>\n",
       "      <td>9.836331e-01</td>\n",
       "      <td>-2.112493e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.200670e-01</td>\n",
       "      <td>7.978915e-03</td>\n",
       "      <td>-2.166058e-02</td>\n",
       "      <td>-9.817942e-03</td>\n",
       "      <td>7.712016e-03</td>\n",
       "      <td>-1.854257e-01</td>\n",
       "      <td>-1.374232e-01</td>\n",
       "      <td>-1.392018e-01</td>\n",
       "      <td>-1.410894e-01</td>\n",
       "      <td>-1.396943e-01</td>\n",
       "      <td>-1.974120e-01</td>\n",
       "      <td>-9.287928e-02</td>\n",
       "      <td>-1.360219e-01</td>\n",
       "      <td>-8.275262e-02</td>\n",
       "      <td>-1.099900e-01</td>\n",
       "      <td>4.635254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.113415e+00</td>\n",
       "      <td>4.690489e-01</td>\n",
       "      <td>1.113415e+00</td>\n",
       "      <td>5.061551e+02</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>1.260000e+02</td>\n",
       "      <td>1.397919e+00</td>\n",
       "      <td>4.058502e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.246517e+02</td>\n",
       "      <td>9.861582e+00</td>\n",
       "      <td>4.390453e+00</td>\n",
       "      <td>4.018719e+00</td>\n",
       "      <td>4.267157e+00</td>\n",
       "      <td>4.148237e+00</td>\n",
       "      <td>4.161892e+00</td>\n",
       "      <td>4.976705e+00</td>\n",
       "      <td>4.823559e+00</td>\n",
       "      <td>4.248556e+00</td>\n",
       "      <td>4.528584e+00</td>\n",
       "      <td>4.468755e+01</td>\n",
       "      <td>5.848133e+01</td>\n",
       "      <td>5.110862e+01</td>\n",
       "      <td>6.084403e+01</td>\n",
       "      <td>5.558117e+01</td>\n",
       "      <td>8.415044e+02</td>\n",
       "      <td>1.466222e+01</td>\n",
       "      <td>1.404666e+01</td>\n",
       "      <td>1.247740e+01</td>\n",
       "      <td>1.105094e+01</td>\n",
       "      <td>2.291351e+01</td>\n",
       "      <td>1.799426e-02</td>\n",
       "      <td>2.522155e+01</td>\n",
       "      <td>1.646691e+01</td>\n",
       "      <td>1.637772e+01</td>\n",
       "      <td>1.384021e+01</td>\n",
       "      <td>2.344061e+00</td>\n",
       "      <td>2.255432e+00</td>\n",
       "      <td>6.986265e+00</td>\n",
       "      <td>1.610170e+01</td>\n",
       "      <td>1.532776e+01</td>\n",
       "      <td>1.578751e+01</td>\n",
       "      <td>1.550149e+01</td>\n",
       "      <td>1.576292e+01</td>\n",
       "      <td>9.619485e-01</td>\n",
       "      <td>2.474810e+00</td>\n",
       "      <td>2.185393e+00</td>\n",
       "      <td>1.509156e+00</td>\n",
       "      <td>1.430763e+00</td>\n",
       "      <td>1.627778e+00</td>\n",
       "      <td>9.809655e+01</td>\n",
       "      <td>6.225093e+01</td>\n",
       "      <td>5.605258e+01</td>\n",
       "      <td>5.937551e+01</td>\n",
       "      <td>3.032129e+01</td>\n",
       "      <td>3.302482e+01</td>\n",
       "      <td>3.400017e+01</td>\n",
       "      <td>3.614580e+01</td>\n",
       "      <td>3.606934e+01</td>\n",
       "      <td>5.349727e+00</td>\n",
       "      <td>5.021693e+00</td>\n",
       "      <td>4.868938e+00</td>\n",
       "      <td>5.148589e+00</td>\n",
       "      <td>4.885100e+00</td>\n",
       "      <td>9.875965e+01</td>\n",
       "      <td>6.280362e+01</td>\n",
       "      <td>5.673197e+01</td>\n",
       "      <td>5.982170e+01</td>\n",
       "      <td>3.017816e+01</td>\n",
       "      <td>3.288096e+01</td>\n",
       "      <td>3.385904e+01</td>\n",
       "      <td>3.614530e+01</td>\n",
       "      <td>3.590375e+01</td>\n",
       "      <td>5.351632e+00</td>\n",
       "      <td>5.022384e+00</td>\n",
       "      <td>4.870565e+00</td>\n",
       "      <td>5.149505e+00</td>\n",
       "      <td>4.886768e+00</td>\n",
       "      <td>1.610934e+00</td>\n",
       "      <td>9.627053e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.742754e+01</td>\n",
       "      <td>2.362395e+01</td>\n",
       "      <td>3.335767e+01</td>\n",
       "      <td>2.533665e+01</td>\n",
       "      <td>2.685993e+01</td>\n",
       "      <td>7.336961e+00</td>\n",
       "      <td>1.027253e+01</td>\n",
       "      <td>8.664094e+00</td>\n",
       "      <td>1.190624e+01</td>\n",
       "      <td>9.475973e+00</td>\n",
       "      <td>5.855596e+00</td>\n",
       "      <td>5.646033e+00</td>\n",
       "      <td>5.436654e+00</td>\n",
       "      <td>5.893595e+00</td>\n",
       "      <td>5.482180e+00</td>\n",
       "      <td>2.097920e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              click    conversion     treatment            f0            f1  \\\n",
       "count  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06   \n",
       "mean   3.329111e-01  6.808859e-02  2.017062e+00  1.297720e-14 -4.963344e-14   \n",
       "std    4.712551e-01  2.518979e-01  1.476708e+00  1.000000e+00  1.000000e+00   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00 -1.693189e+01 -1.859227e+01   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00 -3.227170e-01 -6.600557e-02   \n",
       "50%    0.000000e+00  0.000000e+00  3.000000e+00  1.931761e-01  2.148981e-01   \n",
       "75%    1.000000e+00  0.000000e+00  3.000000e+00  5.738536e-01  4.690489e-01   \n",
       "max    1.000000e+00  1.000000e+00  4.000000e+00  1.113415e+00  4.690489e-01   \n",
       "\n",
       "                 f2            f3            f4            f5            f6  \\\n",
       "count  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06   \n",
       "mean   1.297720e-14  1.858299e-15  1.132534e+01  4.847851e+01  1.226735e-14   \n",
       "std    1.000000e+00  1.000000e+00  3.345643e+00  3.750672e+01  1.000000e+00   \n",
       "min   -1.693189e+01 -1.762771e+00  0.000000e+00  0.000000e+00 -9.178679e+00   \n",
       "25%   -3.227170e-01 -4.720464e-01  1.200000e+01  1.600000e+01 -4.414899e-01   \n",
       "50%    1.931761e-01 -1.182385e-01  1.200000e+01  3.800000e+01  1.775416e-01   \n",
       "75%    5.738536e-01  3.220868e-01  1.300000e+01  8.000000e+01  6.475521e-01   \n",
       "max    1.113415e+00  5.061551e+02  1.500000e+01  1.260000e+02  1.397919e+00   \n",
       "\n",
       "                 f7            f8            f9           f10           f11  \\\n",
       "count  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06   \n",
       "mean   4.893479e-14  2.055761e-01 -7.029400e-15 -1.531296e-14 -9.767474e-17   \n",
       "std    1.000000e+00  7.129533e-01  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -1.843498e+00 -1.000000e+00 -5.200102e-01 -7.789905e-01 -5.813451e-01   \n",
       "25%   -1.327731e-01  0.000000e+00 -2.742315e-01 -4.391719e-01 -5.067518e-01   \n",
       "50%    1.238355e-01  0.000000e+00 -1.242107e-01 -3.329785e-01 -3.579026e-01   \n",
       "75%    4.659804e-01  1.000000e+00  6.581565e-02  9.179482e-02 -5.328518e-02   \n",
       "max    4.058502e+00  1.000000e+00  4.246517e+02  9.861582e+00  4.390453e+00   \n",
       "\n",
       "                f12           f13           f14           f15           f16  \\\n",
       "count  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06   \n",
       "mean  -1.433504e-15 -7.158479e-16  1.729946e-15 -1.000455e-16  5.403623e-16   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -5.791204e-01 -5.811981e-01 -5.869710e-01 -5.800899e-01 -5.300433e-01   \n",
       "25%   -5.078609e-01 -5.066932e-01 -5.163263e-01 -5.067766e-01 -4.689983e-01   \n",
       "50%   -3.596122e-01 -3.580425e-01 -3.674336e-01 -3.580768e-01 -3.429138e-01   \n",
       "75%   -5.739824e-02 -5.632193e-02 -3.592680e-02 -6.044801e-02 -1.121515e-01   \n",
       "max    4.018719e+00  4.267157e+00  4.148237e+00  4.161892e+00  4.976705e+00   \n",
       "\n",
       "                f17           f18           f19           f20           f21  \\\n",
       "count  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06   \n",
       "mean   1.206037e-15  3.792545e-16  5.069362e-17  8.647477e-16 -2.808954e-15   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -5.297176e-01 -5.329927e-01 -5.291009e-01 -2.051438e+00 -2.653362e+00   \n",
       "25%   -4.691352e-01 -4.762073e-01 -4.700291e-01 -4.231365e-01 -4.747444e-01   \n",
       "50%   -3.430104e-01 -3.508452e-01 -3.437702e-01 -6.377253e-02 -8.690667e-02   \n",
       "75%   -1.071805e-01 -9.039800e-02 -1.084009e-01  3.094021e-01  3.902922e-01   \n",
       "max    4.823559e+00  4.248556e+00  4.528584e+00  4.468755e+01  5.848133e+01   \n",
       "\n",
       "                f22           f23           f24           f25           f26  \\\n",
       "count  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06   \n",
       "mean   1.551954e-15  1.049387e-15 -1.744694e-15  1.477405e-15  3.019315e-16   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.330228e+00 -2.704713e+00 -2.528168e+00 -1.517285e+00 -9.260579e-01   \n",
       "25%   -4.453657e-01 -4.904300e-01 -4.626802e-01 -5.158690e-01 -6.490426e-01   \n",
       "50%   -5.668423e-02 -8.737832e-02 -5.714237e-02 -1.128599e-01 -3.212653e-01   \n",
       "75%    3.395765e-01  4.384148e-01  3.622780e-01  4.366980e-01  2.748252e-01   \n",
       "max    5.110862e+01  6.084403e+01  5.558117e+01  8.415044e+02  1.466222e+01   \n",
       "\n",
       "                f27           f28           f29           f30           f31  \\\n",
       "count  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06   \n",
       "mean   1.888722e-14 -2.648952e-15 -1.580736e-15 -4.773777e-16  2.719365e-14   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -1.073056e+00 -1.071262e+00 -1.003023e+00 -8.562420e-01 -5.557327e+01   \n",
       "25%   -7.202621e-01 -6.949100e-01 -6.833392e-01 -6.743675e-01  1.799426e-02   \n",
       "50%   -2.666705e-01 -3.185583e-01 -2.884357e-01 -3.044184e-01  1.799426e-02   \n",
       "75%    4.389164e-01  4.341451e-01  3.697367e-01  3.362756e-01  1.799426e-02   \n",
       "max    1.404666e+01  1.247740e+01  1.105094e+01  2.291351e+01  1.799426e-02   \n",
       "\n",
       "                f32           f33           f34           f35           f36  \\\n",
       "count  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06   \n",
       "mean  -1.152346e-15  1.982184e-15  2.989136e-15 -4.611154e-14  1.141461e-13   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -5.558729e-01 -5.638750e-01 -5.643321e-01 -1.099974e+00 -1.039632e+00   \n",
       "25%   -4.964323e-01 -4.950359e-01 -4.969681e-01 -6.824317e-01 -1.039632e+00   \n",
       "50%   -3.577375e-01 -3.642416e-01 -3.622400e-01 -1.910238e-01 -1.918246e-01   \n",
       "75%    3.853335e-02  4.879281e-02  4.500623e-02  3.889102e-01  7.707515e-01   \n",
       "max    2.522155e+01  1.646691e+01  1.637772e+01  1.384021e+01  2.344061e+00   \n",
       "\n",
       "                f37           f38           f39           f40           f41  \\\n",
       "count  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06   \n",
       "mean   5.541246e-14 -1.341142e-13 -4.068228e-15  1.854724e-15  2.773904e-15   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -1.055675e+00 -1.187171e+00 -6.070271e-01 -5.843887e-01 -6.042899e-01   \n",
       "25%   -1.055675e+00 -1.187171e+00 -4.486505e-01 -4.371121e-01 -4.440061e-01   \n",
       "50%   -1.573124e-01  1.130237e-01 -2.809577e-01 -2.839296e-01 -2.837222e-01   \n",
       "75%    8.097377e-01  7.739473e-01  6.374419e-02  4.974978e-02  6.065000e-02   \n",
       "max    2.255432e+00  6.986265e+00  1.610170e+01  1.532776e+01  1.578751e+01   \n",
       "\n",
       "                f42           f43           f44           f45           f46  \\\n",
       "count  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06   \n",
       "mean   1.543437e-15 -6.015715e-15  3.699764e-15 -8.055069e-15  3.585170e-14   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -5.967528e-01 -7.773987e+01 -4.972883e+00 -8.965087e-01 -9.136077e-01   \n",
       "25%   -4.417799e-01 -5.885686e-01 -7.685876e-01 -7.296643e-01 -7.660523e-01   \n",
       "50%   -2.840021e-01 -9.233618e-02  3.592400e-01 -5.410105e-01 -5.728889e-01   \n",
       "75%    5.609672e-02  4.253302e-01  8.656915e-01  9.397362e-01  1.249727e+00   \n",
       "max    1.550149e+01  1.576292e+01  9.619485e-01  2.474810e+00  2.185393e+00   \n",
       "\n",
       "                f47           f48           f49           f50           f51  \\\n",
       "count  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06   \n",
       "mean   2.412674e-14 -2.079914e-15  1.707669e-14 -1.223745e-14  1.835816e-14   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -3.941843e+00 -4.073446e+00 -3.897007e+00 -2.379831e-01 -3.036693e-01   \n",
       "25%   -1.184756e+00 -1.207508e+00 -1.154147e+00 -2.379831e-01 -3.036693e-01   \n",
       "50%    3.227102e-01 -5.737069e-02  2.699179e-01 -2.379831e-01 -2.747727e-01   \n",
       "75%    7.824007e-01  8.482851e-01  7.866388e-01 -1.389553e-01 -1.142364e-01   \n",
       "max    1.509156e+00  1.430763e+00  1.627778e+00  9.809655e+01  6.225093e+01   \n",
       "\n",
       "                f52           f53           f54           f55           f56  \\\n",
       "count  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06   \n",
       "mean  -1.023446e-14  3.965333e-15  6.341540e-14  2.078108e-14  1.140032e-13   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.762787e-01 -2.998660e-01 -2.180436e-01 -2.551730e-01 -2.446223e-01   \n",
       "25%   -2.754442e-01 -2.998660e-01 -2.180436e-01 -2.551730e-01 -2.446223e-01   \n",
       "50%   -2.562503e-01 -2.710554e-01 -2.180436e-01 -2.551730e-01 -2.446223e-01   \n",
       "75%   -1.360803e-01 -1.068351e-01 -2.180436e-01 -1.268027e-01 -1.240421e-01   \n",
       "max    5.605258e+01  5.937551e+01  3.032129e+01  3.302482e+01  3.400017e+01   \n",
       "\n",
       "                f57           f58           f59           f60           f61  \\\n",
       "count  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06   \n",
       "mean   4.469076e-14  5.683151e-15 -1.386516e-14 -1.821274e-13 -1.448995e-13   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.366415e-01 -2.546120e-01 -2.883068e-01 -4.042764e-01 -3.554782e-01   \n",
       "25%   -2.366415e-01 -2.546120e-01 -2.883068e-01 -4.042764e-01 -3.554782e-01   \n",
       "50%   -2.366415e-01 -2.546120e-01 -2.883068e-01 -4.042764e-01 -3.554782e-01   \n",
       "75%   -1.467639e-01 -1.396627e-01 -2.883068e-01 -1.519057e-01 -2.569043e-01   \n",
       "max    3.614580e+01  3.606934e+01  5.349727e+00  5.021693e+00  4.868938e+00   \n",
       "\n",
       "                f62           f63           f64           f65           f66  \\\n",
       "count  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06   \n",
       "mean   8.104543e-15 -3.443619e-13  1.545818e-13 -4.948753e-14  2.046312e-14   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -4.104357e-01 -3.898364e-01 -2.386262e-01 -3.050631e-01 -2.779237e-01   \n",
       "25%   -4.104357e-01 -3.898364e-01 -2.386262e-01 -3.050631e-01 -2.770790e-01   \n",
       "50%   -4.104357e-01 -3.898364e-01 -2.386262e-01 -2.759106e-01 -2.576532e-01   \n",
       "75%   -1.359159e-01 -1.834617e-01 -1.389301e-01 -1.139523e-01 -1.360303e-01   \n",
       "max    5.148589e+00  4.885100e+00  9.875965e+01  6.280362e+01  5.673197e+01   \n",
       "\n",
       "                f67           f68           f69           f70           f71  \\\n",
       "count  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06   \n",
       "mean   8.860513e-14  1.135963e-14  3.641478e-15 -3.217927e-14  3.388089e-14   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -3.008847e-01 -2.178310e-01 -2.551620e-01 -2.444910e-01 -2.370746e-01   \n",
       "25%   -3.008847e-01 -2.178310e-01 -2.551620e-01 -2.444910e-01 -2.370746e-01   \n",
       "50%   -2.718582e-01 -2.178310e-01 -2.551620e-01 -2.444910e-01 -2.370746e-01   \n",
       "75%   -1.064071e-01 -2.178310e-01 -1.273467e-01 -1.244082e-01 -1.471972e-01   \n",
       "max    5.982170e+01  3.017816e+01  3.288096e+01  3.385904e+01  3.614530e+01   \n",
       "\n",
       "                f72           f73           f74           f75           f76  \\\n",
       "count  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06   \n",
       "mean  -8.494551e-15  2.398633e-14 -5.253318e-14 -6.736687e-15  1.916000e-13   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.545106e-01 -2.883169e-01 -4.043490e-01 -3.554969e-01 -4.104756e-01   \n",
       "25%   -2.545106e-01 -2.883169e-01 -4.043490e-01 -3.554969e-01 -4.104756e-01   \n",
       "50%   -2.545106e-01 -2.883169e-01 -4.043490e-01 -3.554969e-01 -4.104756e-01   \n",
       "75%   -1.400857e-01 -2.883169e-01 -1.519428e-01 -2.562679e-01 -1.352290e-01   \n",
       "max    3.590375e+01  5.351632e+00  5.022384e+00  4.870565e+00  5.149505e+00   \n",
       "\n",
       "                f77           f78           f79        f80        f81  \\\n",
       "count  4.563026e+06  4.563026e+06  4.563026e+06  4563026.0  4563026.0   \n",
       "mean  -1.341227e-13 -1.148650e-13  9.186658e-13        0.0        0.0   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00        0.0        0.0   \n",
       "min   -3.898741e-01 -1.046829e+00 -2.112493e-01        0.0        0.0   \n",
       "25%   -3.898741e-01 -1.046829e+00 -2.112493e-01        0.0        0.0   \n",
       "50%   -3.898741e-01  2.712521e-01 -2.112493e-01        0.0        0.0   \n",
       "75%   -1.829469e-01  9.836331e-01 -2.112493e-01        0.0        0.0   \n",
       "max    4.886768e+00  1.610934e+00  9.627053e+01        0.0        0.0   \n",
       "\n",
       "             f82           f83           f84           f85           f86  \\\n",
       "count  4563026.0  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06   \n",
       "mean         0.0 -2.054864e-13 -1.436688e-13  7.997414e-14  3.189143e-14   \n",
       "std          0.0  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min          0.0 -3.589764e-01 -4.599073e-01 -4.255688e-01 -4.426721e-01   \n",
       "25%          0.0 -3.589764e-01 -4.559252e-01 -4.255688e-01 -4.379482e-01   \n",
       "50%          0.0 -3.589764e-01 -3.782760e-01 -3.730483e-01 -3.695383e-01   \n",
       "75%          0.0 -1.200670e-01  7.978915e-03 -2.166058e-02 -9.817942e-03   \n",
       "max          0.0  3.742754e+01  2.362395e+01  3.335767e+01  2.533665e+01   \n",
       "\n",
       "                f87           f88           f89           f90           f91  \\\n",
       "count  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06   \n",
       "mean   3.382649e-14  4.331797e-16 -8.919827e-14 -3.326532e-13 -1.550075e-13   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -4.566893e-01 -3.389437e-01 -3.887242e-01 -3.803880e-01 -3.666181e-01   \n",
       "25%   -4.554768e-01 -3.389437e-01 -3.887242e-01 -3.803880e-01 -3.625175e-01   \n",
       "50%   -3.784807e-01 -3.389437e-01 -3.278027e-01 -3.502397e-01 -3.133113e-01   \n",
       "75%    7.712016e-03 -1.854257e-01 -1.374232e-01 -1.392018e-01 -1.410894e-01   \n",
       "max    2.685993e+01  7.336961e+00  1.027253e+01  8.664094e+00  1.190624e+01   \n",
       "\n",
       "                f92           f93           f94           f95           f96  \\\n",
       "count  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06  4.563026e+06   \n",
       "mean  -2.684486e-13  4.524844e-14 -5.131995e-15 -3.978028e-14 -2.948881e-15   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -3.934802e-01 -3.347722e-01 -4.481766e-01 -3.995944e-01 -4.602061e-01   \n",
       "25%   -3.934802e-01 -3.347722e-01 -4.481766e-01 -3.995944e-01 -4.435368e-01   \n",
       "50%   -3.370833e-01 -3.347722e-01 -3.522048e-01 -3.627339e-01 -3.479977e-01   \n",
       "75%   -1.396943e-01 -1.974120e-01 -9.287928e-02 -1.360219e-01 -8.275262e-02   \n",
       "max    9.475973e+00  5.855596e+00  5.646033e+00  5.436654e+00  5.893595e+00   \n",
       "\n",
       "                f97           f98  \n",
       "count  4.563026e+06  4.563026e+06  \n",
       "mean   3.773022e-14 -7.525065e-16  \n",
       "std    1.000000e+00  1.000000e+00  \n",
       "min   -4.313790e-01 -4.935589e+01  \n",
       "25%   -4.313790e-01 -6.163251e-01  \n",
       "50%   -3.565239e-01 -8.473487e-02  \n",
       "75%   -1.099900e-01  4.635254e-01  \n",
       "max    5.482180e+00  2.097920e+01  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df_criteo_ori.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b2b8d30-2dae-43b0-93fa-23dd3446da07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    1646545\n",
      "0    1269914\n",
      "4     699450\n",
      "2     519355\n",
      "1     427762\n",
      "Name: treatment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "value_counts = df_criteo_ori['treatment'].value_counts()\n",
    "\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ede53c9-b837-48dc-bc0f-440d9b223bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2041521 (2041521, 96) (729116, 96) 2916459 (145822, 96)\n",
      "CPU times: user 4.67 s, sys: 3.54 s, total: 8.21 s\n",
      "Wall time: 8.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sample = 1.0\n",
    "random_state=20220720\n",
    "df_criteo=df_criteo_ori[(df_criteo_ori['treatment'] == 0) | (df_criteo_ori['treatment'] == 3)].sample(frac=sample, random_state=random_state).reset_index(drop=True)\n",
    "# Change 'treatment' from 3 to 1 in df_criteo_ori\n",
    "df_criteo['treatment'] = df_criteo['treatment'].replace(3, 1)\n",
    "\n",
    "# X = df_criteo[['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11']].values\n",
    "\n",
    "# X[:, 0] = scaling(X[:, 0], min=np.min(X[:, 0]), max=np.max(X[:, 0]))\n",
    "# X[:, 1] = scaling(X[:, 1], min=np.min(X[:, 1]), max=np.max(X[:, 1]))\n",
    "# X[:, 2] = scaling(X[:, 2], min=np.min(X[:, 2]), max=np.max(X[:, 2]))\n",
    "# X[:, 3] = scaling(X[:, 3], min=np.min(X[:, 3]), max=np.max(X[:, 3]))\n",
    "# X[:, 4] = scaling(X[:, 4], min=np.min(X[:, 4]), max=np.max(X[:, 4]))\n",
    "# X[:, 5] = scaling(X[:, 5], min=np.min(X[:, 5]), max=np.max(X[:, 5]))\n",
    "# X[:, 6] = scaling(X[:, 6], min=np.min(X[:, 6]), max=np.max(X[:, 6]))\n",
    "# X[:, 7] = scaling(X[:, 7], min=np.min(X[:, 7]), max=np.max(X[:, 7]))\n",
    "# X[:, 8] = scaling(X[:, 8], min=np.min(X[:, 8]), max=np.max(X[:, 8]))\n",
    "# X[:, 9] = scaling(X[:, 9], min=np.min(X[:, 9]), max=np.max(X[:, 9]))\n",
    "# X[:, 10] = scaling(X[:, 10], min=np.min(X[:, 10]), max=np.max(X[:, 10]))\n",
    "# X[:, 11] = scaling(X[:, 11], min=np.min(X[:, 11]), max=np.max(X[:, 11]))\n",
    "# # \n",
    "columns = [f'f{i}' for i in range(99) if not (80 <= i <= 82)] \n",
    "X = df_criteo[columns].values\n",
    "# \n",
    "for i in range(X.shape[1]):\n",
    "    # \n",
    "    if i not in [80, 81, 82]:\n",
    "        X[:, i] = scaling(X[:, i], min=np.min(X[:, i]), max=np.max(X[:, i]))\n",
    "\n",
    "T = df_criteo['treatment'].values.reshape(-1, 1)\n",
    "Y_visit = df_criteo['click'].values.reshape(-1, 1)\n",
    "Y_conv = df_criteo['conversion'].values.reshape(-1, 1)\n",
    "\n",
    "T.shape, Y_visit.shape, Y_conv.shape\n",
    "\n",
    "\n",
    "# calculate len\n",
    "train_len = int(len(X) * 0.70)\n",
    "cali_len = int(len(X) * 0.05)\n",
    "test_len = len(X) - train_len - cali_len\n",
    "\n",
    "# obtain train set\n",
    "X_train = X[:train_len, :]\n",
    "T_train = T[:train_len, :]\n",
    "Y_visit_train = Y_visit[:train_len, :]\n",
    "Y_conv_train = Y_conv[:train_len, :]\n",
    "\n",
    "# obtain calibration set\n",
    "X_cali = X[train_len:train_len+cali_len, :]\n",
    "T_cali = T[train_len:train_len+cali_len, :]\n",
    "Y_visit_cali = Y_visit[train_len:train_len+cali_len, :]\n",
    "Y_conv_cali = Y_conv[train_len:train_len+cali_len, :]\n",
    "\n",
    "# obtain test set\n",
    "X_test = X[train_len+cali_len:, :]\n",
    "T_test = T[train_len+cali_len:, :]\n",
    "Y_visit_test = Y_visit[train_len+cali_len:, :]\n",
    "Y_conv_test = Y_conv[train_len+cali_len:, :]\n",
    "\n",
    "print(train_len, X_train.shape, X_test.shape, len(X), X_cali.shape)\n",
    "\n",
    "# make covariate shift\n",
    "# condition_cali = (X_cali[:, 0] > 0.3) & (X_cali[:, 1] < 0.7)\n",
    "# X_cali = X_cali[condition_cali]\n",
    "# T_cali = T_cali[condition_cali]\n",
    "# Y_visit_cali = Y_visit_cali[condition_cali]\n",
    "# Y_conv_cali = Y_conv_cali[condition_cali]\n",
    "\n",
    "# condition_test = (X_test[:, 0] > 0.3) & (X_test[:, 1] < 0.7)\n",
    "# X_test = X_test[condition_test]\n",
    "# T_test = T_test[condition_test]\n",
    "# Y_visit_test = Y_visit_test[condition_test]\n",
    "# Y_conv_test = Y_conv_test[condition_test]\n",
    "\n",
    "# print(train_len, X_train.shape, X_test.shape, len(X), X_cali.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e46bfb-1c9e-47d3-805e-c3169fe3a117",
   "metadata": {},
   "source": [
    "# First, on the train set:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78b1270-59d6-415a-9aaf-0a7b4ef2417e",
   "metadata": {},
   "source": [
    "### (i) Train DRP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd0de9d-2a1a-4d98-bada-fa7c5152904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# DPR on train set\n",
    "sys.path.append(\"..\")\n",
    "from model.uplift_model import *\n",
    "\n",
    "count = 1\n",
    "# 2.5e-5\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from model.roi_model import *\n",
    "\n",
    "# final_model = get_roi_rank_criteo_model()\n",
    "# final_model.compile(loss=None, optimizer='adam')\n",
    "#lambda y_true,y_pred: y_pred\n",
    "# print('trainable_weights')\n",
    "# for x in final_model.trainable_weights:\n",
    "#     print(x.name)\n",
    "# print('non_trainable_weights')\n",
    "# for x in final_model.non_trainable_weights:\n",
    "#     print(x.name)\n",
    "# final_model.summary()\n",
    "\n",
    "for i in range(count):\n",
    "\n",
    "    print(\"iteration = \", i + 1)\n",
    "    \n",
    "    final_model = get_roi_rank_model()\n",
    "    final_model.compile(loss=None, optimizer='adam')\n",
    "\n",
    "    mcp_save = ModelCheckpoint('../model_file/roi/criteo/final_model/roi_rank/roi_rank_criteo_model_{}_{}.h5'.format(i+1, sample), save_best_only=False, monitor='val_loss', mode='min', save_weights_only=True)\n",
    "    history = final_model.fit([X_train, T_train, Y_conv_train, Y_visit_train], validation_split=0.2, epochs=1000, batch_size=2000000, shuffle=True, verbose=1, callbacks=[mcp_save,TerminateOnNegative()])\n",
    "    plot_loss(history, \"loss\", \"val_loss\", \"obj\", \"val_obj\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a19cce-248a-406a-96fb-e5c8c7a7bc20",
   "metadata": {},
   "source": [
    "# Second, on the calibration set:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bd3a25-5f42-4b9f-ba38-f83636a60b5e",
   "metadata": {},
   "source": [
    "### (i) Infer DRP model to obtain $\\hat{roi}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25db587d-e5af-4f80-a6b4-021b99d92d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration =  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-20 15:38:33.150450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22288 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:1f:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cali\n",
      "4557/4557 [==============================] - 10s 2ms/step\n",
      "AUCC =  0.7202660262850933\n",
      "\n",
      "\n",
      "CPU times: user 17 s, sys: 1.16 s, total: 18.1 s\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sklearn \n",
    "import sklearn.metrics\n",
    "from metric.Metric import *\n",
    "sys.path.append(\"..\")\n",
    "from model.roi_model import *\n",
    "\n",
    "count = 1\n",
    "\n",
    "DRP_aucc_cali_list = []\n",
    "roi_rank_pre_cali_list = []\n",
    "for i in range(count):\n",
    "    \n",
    "    print(\"iteration = \", i + 1)\n",
    "    \n",
    "    final_model = get_roi_rank_model()\n",
    "    final_model.load_weights('../model_file/roi/criteo/final_model/roi_rank/roi_rank_criteo_model_{}_{}.h5'.format(i+1, sample))\n",
    "\n",
    "    print(\"cali\")\n",
    "    roi_rank_pre_cali = final_model.predict([X_cali, T_cali, Y_conv_cali, Y_visit_cali])\n",
    "    DRP_aucc = get_uplift_model_aucc_no_show(t=(T_cali > 0.5).flatten(), y_reward=Y_conv_cali.flatten(), y_cost=Y_visit_cali.flatten(), roi_pred=roi_rank_pre_cali.flatten(), quantile=200)\n",
    "    roi_rank_pre_cali_list.append(roi_rank_pre_cali)\n",
    "    DRP_aucc_cali_list.append(DRP_aucc)\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708cc4d5-b06c-489a-84ce-c6c2926f486f",
   "metadata": {},
   "source": [
    "### (ii) Calculate $roi^*$ by Algorithm 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a0c283d-efa7-4633-a026-4ed9ee244b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1526/1185985485.py:17: DeprecationWarning: scipy.misc.derivative is deprecated in SciPy v1.10.0; and will be completely removed in SciPy v1.12.0. You may consider using findiff: https://github.com/maroba/findiff or numdifftools: https://github.com/pbrod/numdifftools\n",
      "  deriv = derivative(func_fixed_y, si, dx=1e-6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.misc import derivative\n",
    "from scipy.special import expit as sigmoid\n",
    "from scipy.special import logit\n",
    "\n",
    "def func(ti, yr, yc, si):\n",
    "    qi = sigmoid(si)\n",
    "    if ti == 1:\n",
    "        return - yr*np.log(qi/(1-qi)) - yc*np.log(1-qi)\n",
    "    else:\n",
    "        return yr*np.log(qi/(1-qi)) + yc*np.log(1-qi)\n",
    "\n",
    "    \n",
    "def derivative_values(ti, yr, yc, si):\n",
    "    def func_fixed_y(si_val):\n",
    "        return func(ti, yr, yc, si_val)\n",
    "    deriv = derivative(func_fixed_y, si, dx=1e-6)\n",
    "    return deriv\n",
    "\n",
    "\n",
    "def bst(ti, yr, yc):\n",
    "    epsilon = 1e-5\n",
    "    # corner case\n",
    "    if yr == 0:\n",
    "        return epsilon\n",
    "    elif yc == 0:\n",
    "        return 1 - epsilon\n",
    "    \n",
    "    roi_l = 0.0\n",
    "    roi_r = 1.0\n",
    "    roi_star = (roi_l + roi_r) / 2\n",
    "    \n",
    "\n",
    "    while np.abs(roi_r - roi_l) > epsilon:\n",
    "        derivatives_at_si = derivative_values(ti, yr, yc, logit(roi_star))\n",
    "        if np.abs(derivatives_at_si) < epsilon:\n",
    "            break\n",
    "        if derivatives_at_si > 0:\n",
    "            roi_r = roi_star\n",
    "        else:\n",
    "            roi_l = roi_star\n",
    "        roi_star = (roi_l + roi_r) / 2\n",
    "    return roi_star\n",
    "\n",
    "\n",
    "results = np.zeros(T_cali.shape)\n",
    "\n",
    "# iterate\n",
    "for i in range(T_cali.shape[0]):\n",
    "    # call bst\n",
    "    results[i] = bst(T_cali[i], Y_conv_cali[i], Y_visit_cali[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2db71b3-3193-4045-a266-77ab9a397757",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_roi = np.abs(results - roi_rank_pre_cali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca65dcfd-caea-4361-a714-47deb3e2b29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.90425962e-07, 1.12657355e-06, 1.28193162e-06, ...,\n",
       "       9.99985589e-01, 9.99985828e-01, 9.99986185e-01])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(delta_roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8284cd2b-4200-48b5-89c6-05fa692959e2",
   "metadata": {},
   "source": [
    "### (iii) Infer DRP's MC Dropout model to obtain $\\hat{r}(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07ac30fa-88d9-43f3-99fd-a5ae34e34f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration =  1\n",
      "0\n",
      "cali\n",
      "4557/4557 [==============================] - 12s 3ms/step\n",
      "AUCC =  0.7169969966253281\n",
      "1\n",
      "cali\n",
      "4557/4557 [==============================] - 11s 2ms/step\n",
      "AUCC =  0.721880202053059\n",
      "2\n",
      "cali\n",
      "4557/4557 [==============================] - 12s 3ms/step\n",
      "AUCC =  0.7185034065182082\n",
      "3\n",
      "cali\n",
      "4557/4557 [==============================] - 11s 3ms/step\n",
      "AUCC =  0.716480580521801\n",
      "4\n",
      "cali\n",
      "4557/4557 [==============================] - 11s 2ms/step\n",
      "AUCC =  0.7182949566115989\n",
      "5\n",
      "cali\n",
      "4557/4557 [==============================] - 12s 3ms/step\n",
      "AUCC =  0.720145596486794\n",
      "6\n",
      "cali\n",
      "4557/4557 [==============================] - 11s 2ms/step\n",
      "AUCC =  0.72054982357939\n",
      "7\n",
      "cali\n",
      "4557/4557 [==============================] - 12s 3ms/step\n",
      "AUCC =  0.7201097031818404\n",
      "8\n",
      "cali\n",
      "4557/4557 [==============================] - 12s 3ms/step\n",
      "AUCC =  0.7188971840201609\n",
      "9\n",
      "cali\n",
      "4557/4557 [==============================] - 11s 2ms/step\n",
      "AUCC =  0.7198594823118163\n",
      "\n",
      "\n",
      "CPU times: user 2min 53s, sys: 10.3 s, total: 3min 3s\n",
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sklearn \n",
    "import sklearn.metrics\n",
    "from metric.Metric import *\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "DRP_aucc_cali_mc_list = []\n",
    "\n",
    "for i in range(count):\n",
    "    \n",
    "    print(\"iteration = \", i + 1)\n",
    "    \n",
    "    final_model = get_roi_rank_model_with_dropout()\n",
    "    final_model.load_weights('../model_file/roi/criteo/final_model/roi_rank/roi_rank_criteo_model_{}_{}.h5'.format(i+1, sample))\n",
    "\n",
    "    # multiple prediction\n",
    "    n_iterations = 10\n",
    "    all_predictions_cali = []\n",
    "    \n",
    "    for j in range(n_iterations):\n",
    "        print(j)\n",
    "        \n",
    "        print(\"cali\")\n",
    "        predictions = final_model.predict([X_cali, T_cali, Y_conv_cali, Y_visit_cali])\n",
    "        all_predictions_cali.append(predictions)\n",
    "        DRP_aucc = get_uplift_model_aucc_no_show(t=(T_cali > 0.5).flatten(), y_reward=Y_conv_cali.flatten(), y_cost=Y_visit_cali.flatten(), roi_pred=predictions.flatten(), quantile=200)\n",
    "        DRP_aucc_cali_list.append(DRP_aucc[0])\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "# obtain mean and std\n",
    "mean_pred = np.mean(all_predictions_cali, axis=0)\n",
    "std_pred = np.std(all_predictions_cali, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f0ba50-0b10-4471-ba89-964fd3454008",
   "metadata": {},
   "source": [
    "### (iv) Calculate $\\hat{q}$ by Algorithm 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fec5c6bf-ab40-4a2e-961d-0b55782ddb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scores\n",
    "cal_scores = delta_roi/(std_pred + 1e-5)\n",
    "n = len(cal_scores)\n",
    "\n",
    "# set the error rate\n",
    "alpha = 0.30\n",
    "# Get the score quantile\n",
    "qhat = np.quantile(cal_scores, np.ceil((n+1)*(1-alpha))/n, interpolation='higher')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2375d8c-26b5-4a6d-9ee4-b6e6dc661259",
   "metadata": {},
   "source": [
    "### (v) Select $\\widetilde{roi}$'s equation form from 5a to 5c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "19853b64-3ca5-433a-b558-8347d8fbc87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCC =  0.7209406214095225\n"
     ]
    }
   ],
   "source": [
    "# For mc only\n",
    "\n",
    "\n",
    "ROI_1 = (4.666666*roi_rank_pre_cali + std_pred) # AUCC \n",
    "ROI_2 = roi_rank_pre_cali/(std_pred + 1e5)\n",
    "ROI_3 = 0.95*roi_rank_pre_cali + std_pred\n",
    "DRP_aucc_cali = get_uplift_model_aucc_no_show(t=(T_cali > 0.5).flatten(), y_reward=Y_conv_cali.flatten(), y_cost=Y_visit_cali.flatten(), roi_pred=ROI_3.flatten(), quantile=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "286120ed-8705-472a-beca-e2416160f7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCC =  0.7213974362685069\n"
     ]
    }
   ],
   "source": [
    "ROI_1 = roi_rank_pre_cali*(113.95*roi_rank_pre_cali + qhat*std_pred) # AUCC \n",
    "ROI_2 = roi_rank_pre_cali/(qhat*std_pred + 1e5)\n",
    "ROI_3 = (227.45*roi_rank_pre_cali + qhat*std_pred) #\n",
    "DRP_aucc_cali = get_uplift_model_aucc_no_show(t=(T_cali > 0.5).flatten(), y_reward=Y_conv_cali.flatten(), y_cost=Y_visit_cali.flatten(), roi_pred=ROI_3.flatten(), quantile=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fadec16-d9e2-46a5-828c-ef1e28173b1b",
   "metadata": {},
   "source": [
    "# Third, on the test set:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f233062-4bbe-4a6e-a409-9bb53bf33de6",
   "metadata": {},
   "source": [
    "### (i) Infer DRP model to obtain $\\hat{roi}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02885d2f-e603-4282-ab52-e287125bc6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration =  1\n",
      "22785/22785 [==============================] - 47s 2ms/step\n",
      "AUCC =  0.7223578876322072\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn \n",
    "import sklearn.metrics\n",
    "from metric.Metric import *\n",
    "\n",
    "count = 1\n",
    "sample = 1.0\n",
    "\n",
    "DRP_aucc_test_list = []\n",
    "roi_rank_pre_test_list = []\n",
    "for i in range(count):\n",
    "    \n",
    "    print(\"iteration = \", i + 1)\n",
    "    \n",
    "    final_model = get_roi_rank_model()\n",
    "    final_model.load_weights('../model_file/roi/criteo/final_model/roi_rank/roi_rank_criteo_model_{}_{}.h5'.format(i+1, sample))\n",
    "\n",
    "    roi_rank_pre_test = final_model.predict([X_test, T_test, Y_conv_test, Y_visit_test])\n",
    "    roi_rank_pre_test_list.append(roi_rank_pre_test)\n",
    "    DRP_aucc = get_uplift_model_aucc_no_show(t=(T_test > 0.5).flatten(), y_reward=Y_conv_test.flatten(), y_cost=Y_visit_test.flatten(), roi_pred=roi_rank_pre_test.flatten(), quantile=200)\n",
    "    DRP_aucc_test_list.append(DRP_aucc)\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ae3c129-c2a1-4830-95f2-5838be98e742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aucc =  0.7223578876322072\n"
     ]
    }
   ],
   "source": [
    "# store test aucc for pic \n",
    "import pandas as pd\n",
    "\n",
    "def get_aucc_cost_curve(aucc_list):\n",
    "    delta_cost_list_group = np.array([aucc[1] for aucc in aucc_list])\n",
    "    delta_reward_list_group = np.array([aucc[2] for aucc in aucc_list])\n",
    "    \n",
    "    avg_delta_cost_list = np.mean(delta_cost_list_group, axis=0)\n",
    "    avg_delta_reward_list = np.mean(delta_reward_list_group, axis=0)\n",
    "    \n",
    "    df_aucc_cost_curve = pd.DataFrame(avg_delta_cost_list, columns=['delta_cost'])\n",
    "    df_aucc_cost_curve['delta_reward'] = avg_delta_reward_list\n",
    "    \n",
    "    return df_aucc_cost_curve\n",
    "\n",
    "DRP_avg_aucc_cost_curve = get_aucc_cost_curve(DRP_aucc_test_list)\n",
    "print(\"aucc = \", np.sum(DRP_avg_aucc_cost_curve['delta_reward'].values) / (DRP_avg_aucc_cost_curve['delta_reward'].values[-1] * 201))\n",
    "DRP_avg_aucc_cost_curve.to_csv(\"../figure/mt/a_DRP_avg_aucc_cost_curve_1.0.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea3e188-7e5d-4116-8dfd-a2a8a7faf3f8",
   "metadata": {},
   "source": [
    "### (ii) Infer DRP's MC Dropout to obtain $\\hat{r}(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8b85f09-677c-42af-a4d9-2b54d4f85c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration =  1\n",
      "0\n",
      "test\n",
      "22785/22785 [==============================] - 55s 2ms/step\n",
      "AUCC =  0.7211992024301702\n",
      "1\n",
      "test\n",
      "22785/22785 [==============================] - 60s 3ms/step\n",
      "AUCC =  0.719815928680756\n",
      "2\n",
      "test\n",
      "22785/22785 [==============================] - 60s 3ms/step\n",
      "AUCC =  0.7212853003230847\n",
      "3\n",
      "test\n",
      "22785/22785 [==============================] - 61s 3ms/step\n",
      "AUCC =  0.7212452931140114\n",
      "4\n",
      "test\n",
      "22785/22785 [==============================] - 55s 2ms/step\n",
      "AUCC =  0.7198411037100763\n",
      "5\n",
      "test\n",
      "22785/22785 [==============================] - 58s 3ms/step\n",
      "AUCC =  0.7211516023028189\n",
      "6\n",
      "test\n",
      "22785/22785 [==============================] - 56s 2ms/step\n",
      "AUCC =  0.7211653440804371\n",
      "7\n",
      "test\n",
      "22785/22785 [==============================] - 58s 3ms/step\n",
      "AUCC =  0.7214829483225055\n",
      "8\n",
      "test\n",
      "22785/22785 [==============================] - 56s 2ms/step\n",
      "AUCC =  0.7208709349544241\n",
      "9\n",
      "test\n",
      "22785/22785 [==============================] - 56s 2ms/step\n",
      "AUCC =  0.7209984000372961\n",
      "\n",
      "\n",
      "1708415573.3238635\n",
      "CPU times: user 14min 30s, sys: 56.5 s, total: 15min 27s\n",
      "Wall time: 10min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "import sklearn \n",
    "import sklearn.metrics\n",
    "from metric.Metric import *\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "sys.path.append(\"..\")\n",
    "from model.uplift_model import *\n",
    "from model.roi_model import *\n",
    "\n",
    "\n",
    "count = 1\n",
    "sample = 1.0\n",
    "\n",
    "DRP_aucc_test_mc_list = []\n",
    "\n",
    "for i in range(count):\n",
    "    \n",
    "    print(\"iteration = \", i + 1)\n",
    "    \n",
    "    final_model = get_roi_rank_model_with_dropout()\n",
    "    final_model.load_weights('../model_file/roi/criteo/final_model/roi_rank/roi_rank_criteo_model_{}_{}.h5'.format(i+1, sample))\n",
    "\n",
    "    # multiple prediction\n",
    "    n_iterations = 10\n",
    "    all_predictions_test = []\n",
    "    \n",
    "    for j in range(n_iterations):\n",
    "        print(j)\n",
    "        \n",
    "        print(\"test\")\n",
    "        predictions = final_model.predict([X_test, T_test, Y_conv_test, Y_visit_test])\n",
    "        all_predictions_test.append(predictions)\n",
    "        DRP_aucc_mc = get_uplift_model_aucc_no_show(t=(T_test > 0.5).flatten(), y_reward=Y_conv_test.flatten(), y_cost=Y_visit_test.flatten(), roi_pred=predictions.flatten(), quantile=200)\n",
    "        DRP_aucc_test_mc_list.append(DRP_aucc_mc[0])\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "# cal std and mean\n",
    "mean_pred_test = np.mean(all_predictions_test, axis=0)\n",
    "std_pred_test = np.std(all_predictions_test, axis=0)\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c729ede8-1c81-4ceb-8424-5903a6fec6e5",
   "metadata": {},
   "source": [
    "### (iii) With $\\hat{q}$  and the selected expression, $\\widetilde{roi}(x_{test})$ is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a493425-d1b2-460e-9018-5b9a3c0bfb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCC =  0.7253356268240889\n",
      "aucc =  0.7253356268240889\n"
     ]
    }
   ],
   "source": [
    "# # calculate DRP-MC aucc\n",
    "rDRP_aucc_test_list = []\n",
    "ROI_1 = (0.95*roi_rank_pre_test + std_pred_test) # \n",
    "rDRP_aucc = get_uplift_model_aucc_no_show(t=(T_test > 0.5).flatten(), y_reward=Y_conv_test.flatten(), y_cost=Y_visit_test.flatten(), roi_pred=ROI_1.flatten(), quantile=200)\n",
    "rDRP_aucc_test_list.append(rDRP_aucc)\n",
    "\n",
    "# save DRP-MC AUCC result\n",
    "\n",
    "rDRP_avg_aucc_cost_curve = get_aucc_cost_curve(rDRP_aucc_test_list)\n",
    "print(\"aucc = \", np.sum(rDRP_avg_aucc_cost_curve['delta_reward'].values) / (rDRP_avg_aucc_cost_curve['delta_reward'].values[-1] * 201))\n",
    "rDRP_avg_aucc_cost_curve.to_csv(\"../figure/mt/a_DRP_MC_avg_aucc_cost_curve_1.0.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f42682ef-b608-458d-9246-3724b50361c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCC =  0.7290035664594612\n",
      "aucc =  0.7290035664594612\n"
     ]
    }
   ],
   "source": [
    "# calculate rDRP aucc\n",
    "rDRP_aucc_test_list = []\n",
    "ROI_1 = (227.45*roi_rank_pre_test + qhat*std_pred_test)# \n",
    "rDRP_aucc = get_uplift_model_aucc_no_show(t=(T_test > 0.5).flatten(), y_reward=Y_conv_test.flatten(), y_cost=Y_visit_test.flatten(), roi_pred=ROI_1.flatten(), quantile=200)\n",
    "rDRP_aucc_test_list.append(rDRP_aucc)\n",
    "\n",
    "# save rDRP AUCC result\n",
    "\n",
    "rDRP_avg_aucc_cost_curve = get_aucc_cost_curve(rDRP_aucc_test_list)\n",
    "print(\"aucc = \", np.sum(rDRP_avg_aucc_cost_curve['delta_reward'].values) / (rDRP_avg_aucc_cost_curve['delta_reward'].values[-1] * 201))\n",
    "rDRP_avg_aucc_cost_curve.to_csv(\"../figure/mt/rDRP_avg_aucc_cost_curve_1.0.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee13ea3-7d6f-4d1c-9acf-d61bc7abbd54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4520caeb-5944-4aa2-bbff-824a9b3a519b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
